# In-Sync Replicas

- 지난 시간에 파티션을 복제하여 다른 브로커 상에서 복제물을 만든다는 것을 배웠음



## In-Sync Replicas(ISR)

> Leader 장애시 Leader를 선출하는데 사용

- ISR 은 High water Mark라고 하는 지점까지 동일한 Replica(Leader와 Follower 모두)의 목록
- 진짜로 잘 복제해 가고 있는를 나타내는 지표 (=내가 이해한 바로는, 리더가 될 수 있는 Replica 후보자 느낌)
  - `replica.log.max.messages=4` 
    - 복제를 잘 해가고 있는지, 즉 차
- LOG-END-OFFSET : Leader의 commit offset
- Fully-Replicated Committed : Follower중에 잘 따라 잡는 애가 완전 잘 복제하고 그 복사한 위치가 range 4 안에 있다면 High Water Mark 지점을 의미. 
  - 여기서 commit 은 consumer와 달리 여기까지 복제를 했다는 표시
- Leader는 당연히 ISR
- 못따라 잡고 있는 애들(OSR, Out-of-Sync)을 Leader로 선출하면 안 된다. 

![image-20220420085357196](..\img\image-20220420085357196.png)



### Replica.log.max.messages 사용시 문제점

메시지 유입량이 갑자기 늘어날 경우

- 메시지가 일정하게 kafka 로 들어올 때는 5개 이상 지연되는 경우가 없어서 ISR이 정상 동작
- 갑자기 유입량이 늘어나면 지연으로 판단하고 OSR 상태로 변경시킴

-> 불필요한 에러, Producer에서의 Retry 가 발생한다

그래서

**replica.log.time.mas.ms** 로 판단해야 함! 

- Follower가 Leader로 Fetch요청을 보내는 Interval 확인
  - 이 값이 10000이라면 Follower가 Leader로 Fetch 요청을 10000ms 내에만 요청하면 정상으로 판단

>  Confluent에서는 replica.log.time.max.ms 옵션만 제공(복잡성 제거)



## ISR 은 Leader가 관리 

- ISR 은 해당 파티션의 리더가 떠있는 **브로커**가 관리한다

1. Follower가 느리면 리더는 ISR에서 Follower 103 제거, Zookeeper에 알려줘서 ISR101, 102 유지
2. controller는 파티션 metadate에 대한 변경 사항에 대해 주키퍼로 부터 수신
   - controller : 브로커 중 한대
   - 변경사항을 다른 브로커들에게 파티션 ISR을 알려줌

![image-20220420090556744](..\img\image-20220420090556744.png)



### Controller 

Kafka Cluster 내의 브로커 중 하나가 Controller가 됨 

- Controller는 zookeeper 를 통해 Broker Liveness 를 모니터링 
- Controller는 Leader와 Replica 정보를 Cluster 내의 다른 브로커들에게 전달
- **즉, 컨트롤러는 주키퍼에 Replicas정보의 복사본 유지, 모든 브로커들에게 동일한 정보를 빠른 액세스를 위해 캐시함**
- 리더가 장애나면 (리더가 있는 그 파티션의 브로커가 죽으면) Leader Election 선출을 수행한다. 
- Controller가 장애나면 주키퍼가 Active 브로커들 중에서 선출함

10:00까지 수강